{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d75a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0015ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-x---@ 4 antoinecollas  staff  128 Nov 10 15:33 \u001b[1m\u001b[36msub-CC220352\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff   96 Nov 10 16:11 \u001b[1m\u001b[36msub-CC610631\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff   96 Nov  4 17:36 \u001b[1m\u001b[36msub-CC720986\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff   96 Nov  4 17:37 \u001b[1m\u001b[36msub-CC721292\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff   96 Nov  4 17:38 \u001b[1m\u001b[36msub-CC721519\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff   96 Nov  4 17:38 \u001b[1m\u001b[36msub-CC721888\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff   96 Nov 10 16:06 \u001b[1m\u001b[36msub-CC721894\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff   96 Nov 10 16:36 \u001b[1m\u001b[36msub-CC723395\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "# MEG files\n",
    "%ll camcan/BIDSsep/passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae8dc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-x---@ 3 antoinecollas  staff  96 Nov 10 15:36 \u001b[1m\u001b[36mCC220352\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff  96 Nov 10 16:11 \u001b[1m\u001b[36mCC610631\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff  96 Nov  8 10:54 \u001b[1m\u001b[36mCC720986\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff  96 Nov  8 14:51 \u001b[1m\u001b[36mCC721519\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff  96 Nov 10 16:06 \u001b[1m\u001b[36mCC721894\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 3 antoinecollas  staff  96 Nov 10 16:36 \u001b[1m\u001b[36mCC723395\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "# emptyroom files (no patient during the recording)\n",
    "%ll camcan/emptyroom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5519ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "-rw-r--r--@ 1 antoinecollas  staff  212 Nov 10 15:31 sub-CC220352-trans.fif\r\n",
      "-rw-r--r--@ 1 antoinecollas  staff  212 Nov 10 16:15 sub-CC610631-trans.fif\r\n",
      "-rw-r--r--@ 1 antoinecollas  staff  212 Nov  8 14:48 sub-CC721519-trans.fif\r\n",
      "-rw-r--r--@ 1 antoinecollas  staff  212 Nov 10 16:36 sub-CC723395-trans.fif\r\n"
     ]
    }
   ],
   "source": [
    "# transformation files (head-to-MRI)\n",
    "%ll camcan/trans/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eacfb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-x---@ 9 antoinecollas  staff  288 Nov 10 15:39 \u001b[1m\u001b[36mCC220352\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 9 antoinecollas  staff  288 Nov 10 16:12 \u001b[1m\u001b[36mCC610631\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 9 antoinecollas  staff  288 Nov  8 15:12 \u001b[1m\u001b[36mCC721519\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 9 antoinecollas  staff  288 Nov 10 16:00 \u001b[1m\u001b[36mCC721894\u001b[m\u001b[m/\r\n",
      "drwxr-x---@ 9 antoinecollas  staff  288 Nov 10 16:36 \u001b[1m\u001b[36mCC723395\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "# MRI\n",
    "%ll camcan/freesurfer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f76fdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 antoinecollas  staff  39114 Nov  4 17:31 sss_cal.dat\r\n"
     ]
    }
   ],
   "source": [
    "# CALIBRATION file\n",
    "%ll sss_cal.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f009e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 antoinecollas  staff  47399 Nov  4 17:31 ct_sparse.fif\r\n"
     ]
    }
   ],
   "source": [
    "# CROSSTALK file\n",
    "%ll ct_sparse.fif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d283715",
   "metadata": {},
   "source": [
    "# Load libraries and define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d902d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoreject import get_rejection_threshold\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from nilearn.plotting import plot_stat_map\n",
    "\n",
    "PLOT = True\n",
    "PLOT_3D = PLOT and False\n",
    "\n",
    "# CC720986: good visual ERP tomo\n",
    "SUBJECT = 'CC723395'  # CC220352, CC720986, CC721519\n",
    "# DATA_PATH = '/storage/store/data/camcan/BIDSsep'\n",
    "DATA_PATH = 'camcan/BIDSsep'\n",
    "EMPTYROOM_PATH = 'camcan/emptyroom'\n",
    "FREESURFER_PATH = 'camcan/freesurfer'\n",
    "TRANS_PATH = 'camcan/trans'\n",
    "CALIBRATION_PATH = 'sss_cal.dat'\n",
    "CROSSTALK_PATH = 'ct_sparse.fif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e14e8",
   "metadata": {},
   "source": [
    "# Load raw data and empty room recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b79183",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/d2cp82c54_34yn2drlvfm9ww0000gn/T/ipykernel_43944/3845118813.py:9: RuntimeWarning: This filename (camcan/emptyroom/CC723395/emptyroom_CC723395.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_er = mne.io.read_raw_fif(data_raw_er_file, preload=True, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "data_folder = os.path.join(DATA_PATH, 'passive', 'sub-' + SUBJECT, 'ses-passive')\n",
    "filename = 'sub-' + SUBJECT + '_ses-passive_task-passive_meg.fif'\n",
    "data_raw_file = os.path.join(data_folder, 'meg', filename)\n",
    "raw = mne.io.read_raw_fif(data_raw_file, preload=True, verbose=False)\n",
    "\n",
    "data_er_folder = os.path.join(EMPTYROOM_PATH, SUBJECT)\n",
    "filename = 'emptyroom_' + SUBJECT + '.fif'\n",
    "data_raw_er_file = os.path.join(data_er_folder, filename)\n",
    "raw_er = mne.io.read_raw_fif(data_raw_er_file, preload=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d68eb6",
   "metadata": {},
   "source": [
    "# Plot raw data and psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8a5882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using qt as 2D backend.\n",
      "Using pyopengl with version 3.1.6\n"
     ]
    }
   ],
   "source": [
    "if PLOT:\n",
    "    raw.copy().pick(['meg']).plot(duration=1, start=40, scalings=2*1e-10, n_channels=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd934c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.256 (s)\n"
     ]
    }
   ],
   "source": [
    "if PLOT:\n",
    "    raw.compute_psd().plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d87f2a",
   "metadata": {},
   "source": [
    "# Find bad channels and maxfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "616ba991",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_check = raw.copy()\n",
    "auto_noisy_chs, auto_flat_chs, auto_scores = mne.preprocessing.find_bad_channels_maxwell(\n",
    "    raw.copy(), cross_talk=CROSSTALK_PATH, calibration=CALIBRATION_PATH,\n",
    "    return_scores=True, verbose=False)\n",
    "raw.info['bads'] = auto_noisy_chs + auto_flat_chs\n",
    "raw_er.info['bads'] = raw.info['bads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3ee5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEG0612']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['bads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40aa555f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_sss = mne.preprocessing.maxwell_filter(\n",
    "    raw.copy(), cross_talk=CROSSTALK_PATH, calibration=CALIBRATION_PATH, verbose=False)\n",
    "raw_er_sss = mne.preprocessing.maxwell_filter(\n",
    "    raw_er.copy(), cross_talk=CROSSTALK_PATH, calibration=CALIBRATION_PATH, coord_frame='meg', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7547221",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyopengl with version 3.1.6\n",
      "Using pyopengl with version 3.1.6\n",
      "Effective window size : 0.256 (s)\n",
      "Effective window size : 0.256 (s)\n"
     ]
    }
   ],
   "source": [
    "# plt comparison\n",
    "if PLOT:\n",
    "    raw.copy().pick(['meg']).plot(duration=1.0, start=40.0, scalings=1e-9, n_channels=5)\n",
    "    raw_sss.copy().pick(['meg']).plot(duration=1.0, start=40.0, scalings=1e-9, n_channels=5)\n",
    "    raw.compute_psd().plot()\n",
    "    raw_sss.compute_psd().plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1719c055",
   "metadata": {},
   "source": [
    "# Low pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25c49d57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyopengl with version 3.1.6\n",
      "Effective window size : 0.256 (s)\n"
     ]
    }
   ],
   "source": [
    "raw_sss.filter(l_freq=1, h_freq=30, verbose=False)\n",
    "raw_er_sss.filter(l_freq=1, h_freq=30, verbose=False)\n",
    "# raw_sss.notch_filter(np.arange(50, 201, 50))\n",
    "raw_sss = raw_sss.crop(tmax=130)\n",
    "if PLOT:\n",
    "    raw_sss.copy().pick(['meg']).plot(duration=150.0, start=0.0, scalings=5*1e-11, n_channels=5)\n",
    "    raw_sss.compute_psd().plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30b30d",
   "metadata": {},
   "source": [
    "# Load events, create epochs and evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9b62564",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "event_dict = {'auditory/300Hz': 6, 'auditory/600Hz': 7, 'auditory/1200Hz': 8, 'visual': 9}\n",
    "events = mne.find_events(raw_sss, verbose=False)\n",
    "if PLOT:\n",
    "    fig = mne.viz.plot_events(\n",
    "        events, event_id=event_dict, sfreq=raw_sss.info['sfreq'], first_samp=raw_sss.first_samp)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ced5cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 339, 701)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create epochs\n",
    "TMIN, TMAX = -0.2, 0.5\n",
    "epochs = mne.Epochs(\n",
    "    raw_sss, events, tmin=TMIN, tmax=TMAX, baseline=(TMIN, 0.0), event_id=event_dict, preload=True, verbose=False)\n",
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d3c5a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyopengl with version 3.1.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x4464a72e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed78ea59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mag': 2.0004186496515575e-12, 'grad': 7.130712618029352e-11, 'eog': 0.00047912599931976274}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(82, 339, 701)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reject some epochs\n",
    "reject = get_rejection_threshold(epochs, verbose=False)\n",
    "print(reject)\n",
    "epochs = mne.Epochs(\n",
    "    raw_sss, events, tmin=TMIN, tmax=TMAX, baseline=(TMIN, 0.0), reject=reject,\n",
    "    event_id=event_dict, preload=True, verbose=False)\n",
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84ff68f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evoked = dict()\n",
    "for event in event_dict:\n",
    "    evoked[event] = epochs[event].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70e3267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual\n"
     ]
    }
   ],
   "source": [
    "EVENT = 'visual'\n",
    "# EVENT = 'auditory'\n",
    "if PLOT:\n",
    "    print(EVENT)\n",
    "    epochs[EVENT].average().plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e416481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_times = np.linspace(0.1, 0.3, num=6)\n",
    "if PLOT:\n",
    "    evoked[EVENT].plot_topomap(all_times, ch_type='mag')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ebd7b0",
   "metadata": {},
   "source": [
    "# Compute noise covariance from baseline segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87fe7e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.2e-14 (2.2e-16 eps * 102 dim * 0.95  max singular value)\n",
      "    Estimated rank (mag): 73\n",
      "    MAG: rank 73 computed from 102 data channels with 0 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.2e-13 (2.2e-16 eps * 204 dim * 4.9  max singular value)\n",
      "    Estimated rank (grad): 73\n",
      "    GRAD: rank 73 computed from 204 data channels with 0 projectors\n"
     ]
    }
   ],
   "source": [
    "noise_cov = mne.compute_covariance(epochs, tmax=0, method='auto', rank=None, verbose=False)\n",
    "if PLOT:\n",
    "    noise_cov.plot(raw_sss.info)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bba5b58e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual\n"
     ]
    }
   ],
   "source": [
    "if PLOT:\n",
    "    print(EVENT)\n",
    "    evoked[EVENT].plot_white(noise_cov, time_unit='s', verbose=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc40c74",
   "metadata": {},
   "source": [
    "# Compute noise covariance from empty room recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6570642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyopengl with version 3.1.6\n"
     ]
    }
   ],
   "source": [
    "if PLOT:\n",
    "    raw_er_sss.copy().pick(['meg']).plot(duration=150.0, start=0.0, scalings=5*1e-11, n_channels=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f802f61c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise covariance matrix:\n",
      "Noise covariance matrix empty room:\n"
     ]
    }
   ],
   "source": [
    "noise_cov_er = mne.compute_raw_covariance(raw_er_sss, tmin=0, tmax=None, verbose=False)\n",
    "if PLOT:\n",
    "    print('Noise covariance matrix:')\n",
    "    noise_cov.plot(raw_er.info, show_svd=False)\n",
    "    print('Noise covariance matrix empty room:')\n",
    "    noise_cov_er.plot(raw_er_sss.info, show_svd=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "defca541",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/d2cp82c54_34yn2drlvfm9ww0000gn/T/ipykernel_43944/3374418727.py:3: RuntimeWarning: Something went wrong in the data-driven estimation of the data rank as it exceeds the theoretical rank from the info (74 > 73). Consider setting rank to \"auto\" or setting it explicitly as an integer.\n",
      "  evoked[EVENT].plot_white(noise_cov_er, time_unit='s', verbose=False)\n",
      "/var/folders/gb/d2cp82c54_34yn2drlvfm9ww0000gn/T/ipykernel_43944/3374418727.py:3: RuntimeWarning: Something went wrong in the data-driven estimation of the data rank as it exceeds the theoretical rank from the info (74 > 73). Consider setting rank to \"auto\" or setting it explicitly as an integer.\n",
      "  evoked[EVENT].plot_white(noise_cov_er, time_unit='s', verbose=False)\n"
     ]
    }
   ],
   "source": [
    "if PLOT:\n",
    "    print(EVENT)\n",
    "    evoked[EVENT].plot_white(noise_cov_er, time_unit='s', verbose=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2ee98",
   "metadata": {},
   "source": [
    "# Compute the dSPM inverse solution on the cortical surface "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74275ec8",
   "metadata": {},
   "source": [
    "## Plot the coregistration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf3883d",
   "metadata": {},
   "source": [
    "The coregistration is the operation that allows to position the head and the sensors in a common coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f802b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_file = os.path.join(TRANS_PATH, 'sub-' + SUBJECT + '-trans.fif')\n",
    "if PLOT_3D:\n",
    "    mne.viz.plot_alignment(\n",
    "        raw_sss.info, trans_file, subject=SUBJECT, dig=True,\n",
    "        meg=['helmet', 'sensors'], subjects_dir=FREESURFER_PATH, surfaces='head-dense', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03db37a",
   "metadata": {},
   "source": [
    "## Plot BEM and source space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f27b02",
   "metadata": {},
   "source": [
    "bem = boundary element model\n",
    "\n",
    "The BEM surfaces are the triangulations of the interfaces between different tissues needed for forward computation. These surfaces are for example the inner skull surface, the outer skull surface and the outer skin surface, a.k.a. scalp surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26430cff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# src = mne.setup_source_space(SUBJECT, spacing='oct4', subjects_dir=FREESURFER_PATH, verbose=False)\n",
    "\n",
    "SPHERE = np.array([0, -0.005, 0, 0.085])\n",
    "surface_path = os.path.join(FREESURFER_PATH, SUBJECT, 'bem', 'inner_skull.surf')\n",
    "src = mne.setup_volume_source_space(\n",
    "    SUBJECT, surface=surface_path, subjects_dir=FREESURFER_PATH, sphere=SPHERE, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9805ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using surface: /Users/antoinecollas/Dropbox/postdoc/welcome_duty/camcan/freesurfer/CC723395/bem/inner_skull.surf\n",
      "Using surface: /Users/antoinecollas/Dropbox/postdoc/welcome_duty/camcan/freesurfer/CC723395/bem/outer_skull.surf\n",
      "Using surface: /Users/antoinecollas/Dropbox/postdoc/welcome_duty/camcan/freesurfer/CC723395/bem/outer_skin.surf\n"
     ]
    }
   ],
   "source": [
    "if PLOT:\n",
    "    mne.viz.plot_bem(SUBJECT, subjects_dir=FREESURFER_PATH, src=src)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd28c73",
   "metadata": {},
   "source": [
    "## Plot sources in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77aee4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyvistaqt 3d backend.\n",
      "\n",
      "Getting helmet for system 306m\n",
      "Channel types::\tgrad: 203, mag: 102\n"
     ]
    }
   ],
   "source": [
    "PLOT_3D = True\n",
    "if PLOT_3D:\n",
    "    fig = mne.viz.plot_alignment(info=raw.info, trans=trans_file,\n",
    "        subject=SUBJECT, subjects_dir=FREESURFER_PATH, surfaces='white', coord_frame='mri', src=src)\n",
    "    mne.viz.set_3d_view(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c87f89f",
   "metadata": {},
   "source": [
    "## Make bem model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4abaad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONDUCTIVITY = (0.3, 0.006, 0.3)  # for three layers\n",
    "CONDUCTIVITY = (0.3,)  # for single layer\n",
    "model = mne.make_bem_model(SUBJECT, ico=4, conductivity=CONDUCTIVITY, subjects_dir=FREESURFER_PATH, verbose=False)\n",
    "bem = mne.make_bem_solution(model, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a9eacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leadfield size : 306 sensors x 32235 dipoles\n"
     ]
    }
   ],
   "source": [
    "fwd = mne.make_forward_solution(data_raw_file, trans=trans_file, src=src, bem=bem, verbose=False)\n",
    "leadfield = fwd['sol']['data']\n",
    "print(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "074b23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_operator = mne.minimum_norm.make_inverse_operator(raw_sss.info, fwd, noise_cov, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a19691fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual\n",
      "Showing: t = 0.162 s, (6.0, -54.7, -26.7) mm, [18, 6, 15] vox, 18531 vertex\n",
      "Using control points [ 5.40977085  6.7454156  16.26957795]\n"
     ]
    }
   ],
   "source": [
    "METHOD = 'dSPM'\n",
    "print(EVENT)\n",
    "stc = mne.minimum_norm.apply_inverse(evoked[EVENT], inverse_operator, method=METHOD, verbose=False)\n",
    "if PLOT:\n",
    "    stc.plot(src=src, subjects_dir=FREESURFER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d9ffbb",
   "metadata": {},
   "source": [
    "# Electroocoulogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a7d05e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "eog_evoked = mne.preprocessing.create_eog_epochs(raw_sss, verbose=False).average()\n",
    "eog_evoked.apply_baseline(baseline=(None, -0.2))  # subtract mean signal\n",
    "if PLOT:\n",
    "    eog_evoked.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455fd1c7",
   "metadata": {},
   "source": [
    "# Electrocardiogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f13a8a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "ecg_evoked = mne.preprocessing.create_ecg_epochs(raw_sss, verbose=False).average()\n",
    "ecg_evoked.apply_baseline(baseline=(None, -0.2))\n",
    "ecg_evoked.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdec9f5",
   "metadata": {},
   "source": [
    "# ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "498d2442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 306 channels (please be patient, this may take a while)\n",
      "Selecting by explained variance: 70 components\n",
      "Fitting ICA took 59.2s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Method</th>\n",
       "        <td>picard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Fit</th>\n",
       "        <td>430 iterations on raw data (130001 samples)</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>ICA components</th>\n",
       "        <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Available PCA components</th>\n",
       "        <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Channel types</th>\n",
       "        <td>mag, grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ICA components marked for exclusion</th>\n",
       "        <td>&mdash;</td>\n",
       "    </tr>\n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<ICA | raw data decomposition, method: picard (fit in 430 iterations on 130001 samples), 70 ICA components (306 PCA components available), channel types: mag, grad, no sources marked for exclusion>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica = mne.preprocessing.ICA(n_components=0.999, method='picard', max_iter='auto', random_state=123)\n",
    "ica.fit(raw_sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81f71d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoinecollas/miniforge3/envs/welcome_duty/lib/python3.10/site-packages/mne/viz/_mpl_figure.py:2083: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(FigureClass=FigureClass, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "if PLOT:\n",
    "    ica.plot_components()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b64e4237",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=6, n_times=130001\n",
      "    Range : 24000 ... 154000 =     24.000 ...   154.000 secs\n",
      "Ready.\n",
      "Using pyopengl with version 3.1.6\n"
     ]
    }
   ],
   "source": [
    "BLINK_CHANNELS = [1]\n",
    "HEARTBEAT_CHANNELS = [7, 14]\n",
    "if PLOT:\n",
    "    ica.plot_sources(raw_sss, picks=BLINK_CHANNELS+HEARTBEAT_CHANNELS)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61218b9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (70 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 306 PCA components\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (70 components)\n",
      "    Zeroing out 2 ICA components\n",
      "    Projecting back using 306 PCA components\n"
     ]
    }
   ],
   "source": [
    "if PLOT:\n",
    "    # blinks\n",
    "    ica.plot_overlay(raw_sss, exclude=BLINK_CHANNELS, picks='mag')\n",
    "    # heartbeats\n",
    "    ica.plot_overlay(raw_sss, exclude=HEARTBEAT_CHANNELS, picks='mag')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef13a640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (70 components)\n",
      "    Zeroing out 3 ICA components\n",
      "    Projecting back using 306 PCA components\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>January 16, 1917  15:18:48 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>mne_anonymize</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "            \n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>129 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>204 Gradiometers, 102 Magnetometers, 17 Stimulus, 2 EOG, 1 ECG, 13 misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>EOG061, EOG062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>ECG063</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>1.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>30.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>sub-CC723395_ses-passive_task-passive_meg.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:02:10 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | sub-CC723395_ses-passive_task-passive_meg.fif, 339 x 130001 (130.0 s), ~342.6 MB, data loaded>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica.exclude = BLINK_CHANNELS+HEARTBEAT_CHANNELS\n",
    "reconst_raw_sss = raw_sss.copy()\n",
    "ica.apply(reconst_raw_sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7733d316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual\n",
      "visual\n",
      "Channels marked as bad:\n",
      "none\n",
      "Dropped 0 epochs: \n",
      "The following epochs were marked as bad and are dropped:\n",
      "[]\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "['MEG0612']\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "epochs = mne.Epochs(\n",
    "    raw_sss, events, tmin=TMIN, tmax=TMAX, baseline=(TMIN, 0.0), reject=reject,\n",
    "    event_id=event_dict, preload=True, verbose=False)\n",
    "evoked = dict()\n",
    "for event in event_dict:\n",
    "    evoked[event] = epochs[event].average()\n",
    "if PLOT:\n",
    "    print(EVENT)\n",
    "    evoked[EVENT].plot()\n",
    "    plt.show()\n",
    "\n",
    "epochs = mne.Epochs(\n",
    "    reconst_raw_sss, events, tmin=TMIN, tmax=TMAX, baseline=(TMIN, 0.0), reject=reject,\n",
    "    event_id=event_dict, preload=True, verbose=False)\n",
    "evoked = dict()\n",
    "for event in event_dict:\n",
    "    evoked[event] = epochs[event].average()\n",
    "if PLOT:\n",
    "    print(EVENT)\n",
    "    evoked[EVENT].plot()\n",
    "    plt.show()\n",
    "all_times = np.linspace(0.1, 0.3, num=6)\n",
    "if PLOT:\n",
    "    evoked[EVENT].plot_topomap(all_times, ch_type='mag')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762670cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
